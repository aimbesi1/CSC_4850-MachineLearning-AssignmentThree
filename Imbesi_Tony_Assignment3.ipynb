{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbesi1/CSC_4850-MachineLearning-AssignmentThree/blob/main/Imbesi_Tony_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSC 4850 / 6850 / DSCI 4850 - Assigment 3 - (400/450 points)\n",
        "\n",
        "**Total points (400 undergraduate / 450 graduate)**\n",
        "\n",
        "**Student Name: Tony Imbesi**\n",
        "\n",
        "** *Undergraduate* (select one)**\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "You are to make a copy of this notebook on your own Google Drive (if you don't have one, get one, it is free), and use the exact format provided. Any code needs to go in the code cells, and any 'text' answer/description needs to go in the proper text cell. We will not be looking for answers randomly placed so please read the instructions.\n",
        "\n",
        "You are to use only the libraries provided in the next code cell. Any additional library is NOT allowed and will cause you to lose all the points that use said library's functions/functionality. You can use any functions given in the class code examples, but be very very careful of lifting anything \n",
        "'as-is' from the internet as it will be considerered plagiarism. \n",
        "\n",
        "**IMPORTANT: Make sure you use 1234 (for the folds use: 3456, 5678, 7890) for your randomseed/random states. Failure to do so will make your answers not comparable to the answer key and you will get a zero on the whole assignment.**\n",
        "\n",
        "## Submission format:\n",
        "\n",
        "The submission for Assignment two will have two components:\n",
        "\n",
        "1) You are to create a PDF from the PRINT out of this notebook with all cells executed sequentially. It is the student's responsibility to be able to do this and no excuses will be accepted, no legible PDF = zero grade. So practice and test before submission time. This PDF should be named LastName_FirstName-Assignment3.PDF\n",
        "\n",
        "2) The student should create a GitHub repository for this assignment and properly title the repository Class_CODE-ClassName-AssignmentTwo. This repository should have a readme file and the Google Colab notebook in it. Note that colab can save a copy directly to GitHub so make sure you test this. Downloading the notebook file and uploading it directly will result in 200 points deduction. The link to your GitHub repository should be included as text/message in the iCollege submission drop, failure to include this link will result in a 100 point penalty. \n",
        "\n",
        "## Extra Credit for all:\n",
        "\n",
        "Any student can get 20 extra credit points by doing one simple thing:\n",
        "\n",
        "1) Make sure your repo for this assignment has a nice README file with figures and results. \n"
      ],
      "metadata": {
        "id": "Uc3L9tKWVV4g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjGD5VGFVS-s"
      },
      "outputs": [],
      "source": [
        "############## These are the only imports allowed to solve this homework, so make sure you do not add anything else down below\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Chess dataset from Kaggle: https://www.kaggle.com/datasets/datasnaek/chess"
      ],
      "metadata": {
        "id": "89_ilQegV-MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Manually download it and upload to this istance data sample space\n",
        "### Note DO NOT change these operations or all your answers will be incorrect\n",
        "\n",
        "### Let's do some transformations and extra features on this.\n",
        "df=pd.read_csv('games.csv', encoding='utf-8')\n",
        "\n",
        "# Difference between white rating and black rating - independent variable\n",
        "df['rating_difference']=df['white_rating']-df['black_rating']\n",
        "\n",
        "# White wins flag (1=win vs. 0=not-win) - dependent (target) variable\n",
        "df['white_win']=df['winner'].apply(lambda x: 1 if x=='white' else 0)\n"
      ],
      "metadata": {
        "id": "J_sakm7HV90A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "738b6812-9ca3-4b87-edd9-045f6219445b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e2ed9cdc63a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### Let's do some transformations and extra features on this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'games.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Difference between white rating and black rating - independent variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'games.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this assignment we will be using two columns as features only, and the white_win colum as the label."
      ],
      "metadata": {
        "id": "zTyRQCajE5Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[['rating_difference', 'turns']]\n",
        "y=df['white_win'].values"
      ],
      "metadata": {
        "id": "mv3OV1HJE4VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 (10 points)\n",
        "\n",
        "Use sklearn to split this the data into testing and training data. "
      ],
      "metadata": {
        "id": "0TLvYCXVbHN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=1234)"
      ],
      "metadata": {
        "id": "ZIxSrPxmbGYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Manually (DO NOT use kFold or any built-in functionality) create **THREE** different folds for the training data. "
      ],
      "metadata": {
        "id": "Hl5dZFu7lDg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 2\n",
        "\n",
        "def make_folds(X_train, y_train):\n",
        "\n",
        "  f1_Xtrain, f1_Xtest, f1_ytrain, f1_ytest = train_test_split(X_train, y_train, train_size=0.80, random_state=3456)\n",
        "  f2_Xtrain, f2_Xtest, f2_ytrain, f2_ytest = train_test_split(X_train, y_train, train_size=0.80, random_state=5678)\n",
        "  f3_Xtrain, f3_Xtest, f3_ytrain, f3_ytest = train_test_split(X_train, y_train, train_size=0.80, random_state=7890)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fold1 = {\"X_train\": f1_Xtrain, \"X_test\": f1_Xtest, \"y_train\": f1_ytrain, \"y_test\": f1_ytest}\n",
        "  fold2 = {\"X_train\": f2_Xtrain, \"X_test\": f2_Xtest, \"y_train\": f2_ytrain, \"y_test\": f2_ytest}\n",
        "  fold3 = {\"X_train\": f3_Xtrain, \"X_test\": f3_Xtest, \"y_train\": f3_ytrain, \"y_test\": f3_ytest}\n",
        "\n",
        "  return fold1, fold2, fold3\n",
        "  \n",
        "fold1, fold2, fold3 = make_folds(X_train, y_train)"
      ],
      "metadata": {
        "id": "QDAUtNuAlUyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Create code to build three different SVM models with the following kernels:\n",
        "\n",
        "1.   linear\n",
        "2.   poly\n",
        "3.   rbf"
      ],
      "metadata": {
        "id": "V6grDh8FlVtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 3\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "svm_linear = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "svm_poly = svm.SVC(kernel=\"poly\", random_state=1234)\n",
        "svm_rbf = svm.SVC(kernel=\"rbf\", random_state=1234)"
      ],
      "metadata": {
        "id": "OAmTADedkDN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 (70 points)\n",
        "\n",
        "FOLD 1 - run the first three models with first fold data you created. Output the classification report AND plot its learning curve.\n",
        "\n",
        "\n",
        "In the text cell, following the code block, descibe what findings can be infered from the classification report and learning curve. Mention at least 3 non-trivial observations between the different kernels. "
      ],
      "metadata": {
        "id": "UDBERCfzkTIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 4\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def run_models(fold, svm_linear, svm_poly, svm_rbf):\n",
        "\n",
        "  # Linear\n",
        "\n",
        "  f1_scaledX = StandardScaler().fit(fold[\"X_train\"]).transform(fold[\"X_train\"])\n",
        "  f1_scaledX_test = StandardScaler().fit(fold[\"X_test\"]).transform(fold[\"X_test\"])\n",
        "\n",
        "  svm_linear.fit(f1_scaledX, fold[\"y_train\"])\n",
        "  pred_Y1 = svm_linear.predict(f1_scaledX_test)\n",
        "  print(metrics.classification_report(fold[\"y_test\"], pred_Y1))\n",
        "\n",
        "  sizes1, train_scores1, valid_scores1 = learning_curve(estimator = svm_linear, X = f1_scaledX_test, y=fold[\"y_test\"], shuffle = True, random_state = 1234)\n",
        "\n",
        "  # Poly\n",
        "\n",
        "  svm_poly.fit(fold[\"X_train\"], fold[\"y_train\"])\n",
        "  pred_Y2 = svm_poly.predict(fold[\"X_test\"])\n",
        "  print(metrics.classification_report(fold[\"y_test\"], pred_Y2))\n",
        "\n",
        "  sizes2, train_scores2, valid_scores2 = learning_curve(estimator = svm_poly, X = fold[\"X_test\"], y=fold[\"y_test\"], shuffle = True, random_state = 1234)\n",
        "\n",
        "  # RBF\n",
        "  svm_rbf.fit(fold[\"X_train\"], fold[\"y_train\"])\n",
        "  pred_Y3 = svm_rbf.predict(fold[\"X_test\"])\n",
        "  print(metrics.classification_report(fold[\"y_test\"], pred_Y3))\n",
        "\n",
        "  sizes3, train_scores3, valid_scores3 = learning_curve(estimator = svm_rbf, X = fold[\"X_test\"], y=fold[\"y_test\"], shuffle = True, random_state = 1234)\n",
        "\n",
        "\n",
        "  # Learning curves\n",
        "  f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5), sharey=True)\n",
        "  show_learning_curve(ax1, sizes1, train_scores1, valid_scores1, \"Linear\")\n",
        "  show_learning_curve(ax2, sizes2, train_scores2, valid_scores2, \"Poly\")\n",
        "  show_learning_curve(ax3, sizes3, train_scores3, valid_scores3, \"RBF\")\n",
        "\n",
        "  acc_linear = metrics.accuracy_score(fold[\"y_test\"], pred_Y1)\n",
        "  acc_poly = metrics.accuracy_score(fold[\"y_test\"], pred_Y2)\n",
        "  acc_rbf = metrics.accuracy_score(fold[\"y_test\"], pred_Y3)\n",
        "  return {\"linear\": svm_linear, \"poly\": svm_poly, \"rbf\": svm_rbf}\n",
        "\n",
        "def show_learning_curve(ax, sizes, train_scores, valid_scores, title):\n",
        "  train_mean = train_scores.mean(axis=1)\n",
        "  valid_mean = valid_scores.mean(axis=0)\n",
        "  ax.plot(sizes, train_mean, label = \"Training Error\")\n",
        "  ax.plot(sizes, valid_mean, label = \"Validation Error\")\n",
        "  ax.legend()\n",
        "  ax.set_title(title)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f1_results = run_models(fold1, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "OlQED2C0kSQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) The validation error on the linear kernel model oscillates as the sample size increases relative to the training error, which is the most stable out of the three models tested.\n",
        "\n",
        "2) In all three models, the validation error only increases after 1500 samples. As this pattern is not seen in the other two folds, this suggests this fold's data distribution caused all the models to overfit slightly.\n",
        "\n",
        "3) Inspecting the recall values shows the polynomial model identified the most of class 1, but it also misclassified most of class 0. For this fold, it was much more likely to identify any given sample as class 1."
      ],
      "metadata": {
        "id": "axlGZ10EkumL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 (70 points)\n",
        "\n",
        "FOLD 2 - run the first three models with first fold data you created. Output the classification report AND plot its learning curve.\n",
        "\n",
        "\n",
        "In the text cell, following the code block, descibe what findings can be infered from the classification report and learning curve. Mention at least 3 non-trivial observations between the different kernels. "
      ],
      "metadata": {
        "id": "lGTwCVhZHBVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 5\n",
        "f2_results = run_models(fold2, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "K5I5I-vFHBV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) The polynomial model's tendency to label samples as class 1 is increased compared to what it was on fold 1, but its validation error now decreases with sample sizes past 1500.\n",
        "\n",
        "2) The validation error for each model increases and decreases at the same points on each learning curve. This pattern was also shown in the first fold, but it is more evident here.\n",
        "\n",
        "3) The fact that the validation error decreases with sample size for each model shows that the validation data for this fold was easier to predict compared to the previous fold."
      ],
      "metadata": {
        "id": "5AGzL3oNHBV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6 (70 points)\n",
        "\n",
        "FOLD 3 - run the first three models with first fold data you created. Output the classification report AND plot its learning curve.\n",
        "\n",
        "\n",
        "In the text cell, following the code block, descibe what findings can be infered from the classification report and learning curve. Mention at least 3 non-trivial observations between the different kernels. "
      ],
      "metadata": {
        "id": "bB9uezyvHFc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 6\n",
        "f3_results = run_models(fold3, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "952LKGJCHFc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) In each fold, the polynomial model has consistently lower training and validation error compared to the other two models. But instead of steadily declining after 2000 samples on the learning curve as it did on the previous two folds, the polynomial model's training error sharply increases at that point.\n",
        "\n",
        "2) The polynomial model still heavily favors predictions for class 1. Since it shows this behavior on all three folds, this suggests a problem with the kernel, not with the data.\n",
        "\n",
        "3) The linear and RBF models show very similar performance. The only significant difference between them is the RBF model's lesser validation error near 1500 samples, and even that is not far off from the linear model's error at the same point."
      ],
      "metadata": {
        "id": "4hIeICojHFc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7 (30 points)\n",
        "\n",
        "From the three folds pick the best model for each different type of kernel.\n",
        "\n",
        "Present a table with the following columns from their metrics and model. Remember to make classifications on the test set at this stage.\n",
        "\n",
        "1. Model Name (Kernel)\n",
        "2. Accuracy\n",
        "3. Precision\n",
        "4. Recall\n",
        "5. F1-score\n",
        "6. RMSE\n"
      ],
      "metadata": {
        "id": "D5FbmbFolUE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 7\n",
        "\n",
        "best_linear = f2_results[\"linear\"]\n",
        "best_poly = f2_results[\"poly\"]\n",
        "best_rbf = f2_results[\"rbf\"]\n",
        "\n",
        "def get_metrics(model):\n",
        "  pred_Y = model.predict(X_test)\n",
        "  acc = metrics.accuracy_score(y_test, pred_Y)\n",
        "  precision = metrics.precision_score(y_test, pred_Y)\n",
        "  recall = metrics.recall_score(y_test, pred_Y)\n",
        "  f1_score = metrics.f1_score(y_test, pred_Y)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred_Y))\n",
        "  return [acc, precision, recall, f1_score, rmse]\n",
        "\n",
        "table = pd.DataFrame()\n",
        "table[\"Metric\"] = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"RMSE\"]\n",
        "table[\"Linear - Fold 2\"] = get_metrics(best_linear)\n",
        "table[\"Poly - Fold 2\"] = get_metrics(best_poly)\n",
        "table[\"RBF - Fold 2\"] = get_metrics(best_rbf)\n",
        "\n",
        "table.head()"
      ],
      "metadata": {
        "id": "7-wRvWY7mvJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8 (40 points) \n",
        "\n",
        "From question 7, which one is the best model in the following contexts:\n",
        "\n",
        "a) Metrics from table from question 7, and why?\n",
        "\n",
        "b) Based on the learning curves ploted in the previous questions, and why?"
      ],
      "metadata": {
        "id": "d0uKcXIWm2gZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) The RBF model trained on fold 2 performed the best on the testing data. It has the best accuracy, and its recall, F1-score, and RMSE are all at least slightly better than the linear model. The polynomial model has a much better recall and therefore has a higher F1-score, but the RBF model has better metrics overall."
      ],
      "metadata": {
        "id": "fUv67lIDnQVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) The RBF model trained on fold 2 was the best model on that fold. Its validation error was better at lower sample sizes than the linear model on the learning curves, and it had consistent accuracy when predicting both classes unlike the polynomial model."
      ],
      "metadata": {
        "id": "vekeBSBBnS8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9 (50 points)\n",
        "\n",
        "Wrie the simplest and most efficient Sklearn pipeline to do extactly what we did in questions 2 to 6. Make sure that you get all the same intermediate outputs and output the same table from quetsion 7 directly from this pipeline."
      ],
      "metadata": {
        "id": "5FAvUA_LptZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Question 9\n",
        "\n",
        "def pipe():\n",
        "  fold1, fold2, fold3 = make_folds(X_train, y_train)\n",
        "\n",
        "  svm_linear = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "  svm_poly = svm.SVC(kernel=\"poly\", random_state=1234)\n",
        "  svm_rbf = svm.SVC(kernel=\"rbf\", random_state=1234)\n",
        "  f1_results = run_models(fold1, svm_linear, svm_poly, svm_rbf)\n",
        "\n",
        "  # svm_linear2 = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "  # svm_poly2 = svm.SVC(kernel=\"poly\", random_state=1234)\n",
        "  # svm_rbf2 = svm.SVC(kernel=\"rbf\", random_state=1234)\n",
        "  f2_results = run_models(fold2, svm_linear, svm_poly, svm_rbf)\n",
        "\n",
        "  # svm_linear3 = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "  # svm_poly3 = svm.SVC(kernel=\"poly\", random_state=1234)\n",
        "  # svm_rbf3 = svm.SVC(kernel=\"rbf\", random_state=1234)\n",
        "  f3_results = run_models(fold3, svm_linear, svm_poly, svm_rbf)\n",
        "\n",
        "  best_linear = f2_results[\"linear\"]\n",
        "  best_poly = f2_results[\"poly\"]\n",
        "  best_rbf = f2_results[\"rbf\"]\n",
        "\n",
        "  table = pd.DataFrame()\n",
        "  table[\"Linear - Fold 2\"] = get_metrics(best_linear)\n",
        "  table[\"Poly - Fold 2\"] = get_metrics(best_poly)\n",
        "  table[\"RBF - Fold 2\"] = get_metrics(best_rbf)\n",
        "  table.head()\n",
        "\n",
        "  # best_linear\n",
        "  # best_poly\n",
        "  # best_rbf\n",
        "\n",
        "pipe()"
      ],
      "metadata": {
        "id": "OVEa6yRHpsVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graduate Student Question: (50 points)\n",
        "\n",
        "Use the following function and provide visualizations for the best models for each kernel type from above (looking for three plots to receive full credit). Note: The function might need some small adjustments :)\n"
      ],
      "metadata": {
        "id": "ziqaH6VEuBJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "def Plot_3D(X, X_test, y_test, clf):\n",
        "            \n",
        "    # Specify a size of the mesh to be used\n",
        "    mesh_size = 5\n",
        "    margin = 1\n",
        "\n",
        "    # Create a mesh grid on which we will run our model\n",
        "    x_min, x_max = X.iloc[:, 0].fillna(X.mean()).min() - margin, X.iloc[:, 0].fillna(X.mean()).max() + margin\n",
        "    y_min, y_max = X.iloc[:, 1].fillna(X.mean()).min() - margin, X.iloc[:, 1].fillna(X.mean()).max() + margin\n",
        "    xrange = np.arange(x_min, x_max, mesh_size)\n",
        "    yrange = np.arange(y_min, y_max, mesh_size)\n",
        "    xx, yy = np.meshgrid(xrange, yrange)\n",
        "            \n",
        "    # Calculate predictions on grid\n",
        "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Create a 3D scatter plot with predictions\n",
        "    fig = px.scatter_3d(x=X_test['rating_difference'], y=X_test['turns'], z=y_test, \n",
        "                     opacity=0.8, color_discrete_sequence=['black'])\n",
        "\n",
        "    # Set figure title and colors\n",
        "    fig.update_layout(#title_text=\"Scatter 3D Plot with SVM Prediction Surface\",\n",
        "                      paper_bgcolor = 'white',\n",
        "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
        "                                              color='black',\n",
        "                                              gridcolor='#f0f0f0'),\n",
        "                                   yaxis=dict(backgroundcolor='white',\n",
        "                                              color='black',\n",
        "                                              gridcolor='#f0f0f0'\n",
        "                                              ),\n",
        "                                   zaxis=dict(backgroundcolor='lightgrey',\n",
        "                                              color='black', \n",
        "                                              gridcolor='#f0f0f0', \n",
        "                                              )))\n",
        "    # Update marker size\n",
        "    fig.update_traces(marker=dict(size=1))\n",
        "\n",
        "    # Add prediction plane\n",
        "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=Z, name='SVM Prediction',\n",
        "                              colorscale='RdBu', showscale=False, \n",
        "                              contours = {\"z\": {\"show\": True, \"start\": 0.2, \"end\": 0.8, \"size\": 0.05}}))\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "iP7WWFw6Esqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Graduate Student Question - Figure 1\n",
        "\n",
        "Plot_3D(X, X_test, y_test, best_linear)"
      ],
      "metadata": {
        "id": "a17SE-ZcuALz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Graduate Student Question - Figure 2\n",
        "\n",
        "Plot_3D(X, X_test, y_test, best_poly)"
      ],
      "metadata": {
        "id": "1qjVDoYuKLCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Code block for Graduate Student Question - Figure 3\n",
        "\n",
        "Plot_3D(X, X_test, y_test, best_rbf)"
      ],
      "metadata": {
        "id": "iXfXoPIpKL_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}